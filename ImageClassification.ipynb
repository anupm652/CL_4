{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "29515/29515 [==============================] - 0s 6us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26421880/26421880 [==============================] - 57s 2us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "5148/5148 [==============================] - 0s 0s/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4422102/4422102 [==============================] - 26s 6us/step\n"
     ]
    }
   ],
   "source": [
    "# Load Fashion MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data to fit CNN (add channel dimension for grayscale images)\n",
    "X_train = np.expand_dims(X_train, axis=-1)\n",
    "X_test = np.expand_dims(X_test, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "opt = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 - 112s - loss: 0.4204 - accuracy: 0.8486 - val_loss: 0.3684 - val_accuracy: 0.8611 - 112s/epoch - 60ms/step\n",
      "Epoch 2/10\n",
      "1875/1875 - 98s - loss: 0.2816 - accuracy: 0.8971 - val_loss: 0.3284 - val_accuracy: 0.8815 - 98s/epoch - 52ms/step\n",
      "Epoch 3/10\n",
      "1875/1875 - 61s - loss: 0.2361 - accuracy: 0.9126 - val_loss: 0.2831 - val_accuracy: 0.8953 - 61s/epoch - 32ms/step\n",
      "Epoch 4/10\n",
      "1875/1875 - 58s - loss: 0.2000 - accuracy: 0.9257 - val_loss: 0.2515 - val_accuracy: 0.9110 - 58s/epoch - 31ms/step\n",
      "Epoch 5/10\n",
      "1875/1875 - 45s - loss: 0.1747 - accuracy: 0.9336 - val_loss: 0.2672 - val_accuracy: 0.9063 - 45s/epoch - 24ms/step\n",
      "Epoch 6/10\n",
      "1875/1875 - 53s - loss: 0.1475 - accuracy: 0.9442 - val_loss: 0.2708 - val_accuracy: 0.9100 - 53s/epoch - 28ms/step\n",
      "Epoch 7/10\n",
      "1875/1875 - 49s - loss: 0.1295 - accuracy: 0.9518 - val_loss: 0.2889 - val_accuracy: 0.9110 - 49s/epoch - 26ms/step\n",
      "Epoch 8/10\n",
      "1875/1875 - 53s - loss: 0.1094 - accuracy: 0.9599 - val_loss: 0.3053 - val_accuracy: 0.9115 - 53s/epoch - 28ms/step\n",
      "Epoch 9/10\n",
      "1875/1875 - 56s - loss: 0.0950 - accuracy: 0.9646 - val_loss: 0.3133 - val_accuracy: 0.9105 - 56s/epoch - 30ms/step\n",
      "Epoch 10/10\n",
      "1875/1875 - 54s - loss: 0.0816 - accuracy: 0.9690 - val_loss: 0.3533 - val_accuracy: 0.9097 - 54s/epoch - 29ms/step\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.35330691933631897\n",
      "Test Accuracy: 0.9096999764442444\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.datasets import cifar10\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# # Load the CIFAR-10 dataset\n",
    "# (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# # Normalize pixel values to be between 0 and 1\n",
    "# x_train = x_train / 255.0\n",
    "# x_test = x_test / 255.0\n",
    "\n",
    "# # Define CNN model\n",
    "# model = Sequential([\n",
    "#     Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "#     MaxPooling2D((2, 2)),\n",
    "#     Conv2D(64, (3, 3), activation='relu'),\n",
    "#     MaxPooling2D((2, 2)),\n",
    "#     Conv2D(64, (3, 3), activation='relu'),\n",
    "#     Flatten(),\n",
    "#     Dense(64, activation='relu'),\n",
    "#     Dropout(0.5),  # Dropout regularization to prevent overfitting\n",
    "#     Dense(10, activation='softmax')\n",
    "# ])\n",
    "\n",
    "# # Compile the model\n",
    "# learning_rate = 0.001  # Set learning rate hyperparameter\n",
    "# optimizer = Adam(learning_rate=learning_rate)\n",
    "# model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Train the model\n",
    "# model.fit(x_train, y_train, epochs=10, batch_size=64, validation_data=(x_test, y_test))\n",
    "\n",
    "# # Evaluate the model\n",
    "# loss, accuracy = model.evaluate(x_test, y_test)\n",
    "# print(\"Test Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
